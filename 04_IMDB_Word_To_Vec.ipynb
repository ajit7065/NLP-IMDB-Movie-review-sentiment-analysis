{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8daa8bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"dark_background\")\n",
    "sns.set_palette(\"dark\")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score,accuracy_score,recall_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import itertools\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0235f60f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>one reviewers mentioned watching 1 oz episode ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>wonderful little production br br filming tech...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>basically family little boy jake thinks zombie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>petter mattei love time money visually stunnin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  sentiment                                         text_clean\n",
       "0           0          1  one reviewers mentioned watching 1 oz episode ...\n",
       "1           1          1  wonderful little production br br filming tech...\n",
       "2           2          1  thought wonderful way spend time hot summer we...\n",
       "3           3          0  basically family little boy jake thinks zombie...\n",
       "4           4          1  petter mattei love time money visually stunnin..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"D:\\\\Portfolio\\\\03_IMDB_reviews\\\\IMDB_Preprocessed.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ea36272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49582, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9d2b5bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    24884\n",
       "0    24698\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72730fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['sentiment'].values\n",
    "X = df[['text_clean']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e14a5108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['text_clean'].isnull()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8aee304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling with Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b61aaf85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['one',\n",
       "  'reviewers',\n",
       "  'mentioned',\n",
       "  'watching',\n",
       "  '1',\n",
       "  'oz',\n",
       "  'episode',\n",
       "  'hooked',\n",
       "  'right',\n",
       "  'exactly',\n",
       "  'happened',\n",
       "  'br',\n",
       "  'br',\n",
       "  'first',\n",
       "  'thing',\n",
       "  'struck',\n",
       "  'oz',\n",
       "  'brutality',\n",
       "  'unflinching',\n",
       "  'scenes',\n",
       "  'violence',\n",
       "  'set',\n",
       "  'right',\n",
       "  'word',\n",
       "  'go',\n",
       "  'trust',\n",
       "  'not',\n",
       "  'show',\n",
       "  'faint',\n",
       "  'hearted',\n",
       "  'timid',\n",
       "  'show',\n",
       "  'pulls',\n",
       "  'no',\n",
       "  'punches',\n",
       "  'regards',\n",
       "  'drugs',\n",
       "  'sex',\n",
       "  'violence',\n",
       "  'hardcore',\n",
       "  'classic',\n",
       "  'use',\n",
       "  'word',\n",
       "  'br',\n",
       "  'br',\n",
       "  'called',\n",
       "  'oz',\n",
       "  'nickname',\n",
       "  'given',\n",
       "  'oswald',\n",
       "  'maximum',\n",
       "  'security',\n",
       "  'state',\n",
       "  'penitentary',\n",
       "  'focuses',\n",
       "  'mainly',\n",
       "  'emerald',\n",
       "  'city',\n",
       "  'experimental',\n",
       "  'section',\n",
       "  'prison',\n",
       "  'cells',\n",
       "  'glass',\n",
       "  'fronts',\n",
       "  'face',\n",
       "  'inwards',\n",
       "  'privacy',\n",
       "  'not',\n",
       "  'high',\n",
       "  'agenda',\n",
       "  'em',\n",
       "  'city',\n",
       "  'home',\n",
       "  'many',\n",
       "  'aryans',\n",
       "  'muslims',\n",
       "  'gangstas',\n",
       "  'latinos',\n",
       "  'christians',\n",
       "  'italians',\n",
       "  'irish',\n",
       "  'scuffles',\n",
       "  'death',\n",
       "  'stares',\n",
       "  'dodgy',\n",
       "  'dealings',\n",
       "  'shady',\n",
       "  'agreements',\n",
       "  'never',\n",
       "  'far',\n",
       "  'away',\n",
       "  'br',\n",
       "  'br',\n",
       "  'would',\n",
       "  'say',\n",
       "  'main',\n",
       "  'appeal',\n",
       "  'show',\n",
       "  'due',\n",
       "  'fact',\n",
       "  'goes',\n",
       "  'shows',\n",
       "  'would',\n",
       "  'not',\n",
       "  'dare',\n",
       "  'forget',\n",
       "  'pretty',\n",
       "  'pictures',\n",
       "  'painted',\n",
       "  'mainstream',\n",
       "  'audiences',\n",
       "  'forget',\n",
       "  'charm',\n",
       "  'forget',\n",
       "  'romance',\n",
       "  'oz',\n",
       "  'not',\n",
       "  'mess',\n",
       "  'around',\n",
       "  'first',\n",
       "  'episode',\n",
       "  'ever',\n",
       "  'saw',\n",
       "  'struck',\n",
       "  'nasty',\n",
       "  'surreal',\n",
       "  'could',\n",
       "  'not',\n",
       "  'say',\n",
       "  'ready',\n",
       "  'watched',\n",
       "  'developed',\n",
       "  'taste',\n",
       "  'oz',\n",
       "  'got',\n",
       "  'accustomed',\n",
       "  'high',\n",
       "  'levels',\n",
       "  'graphic',\n",
       "  'violence',\n",
       "  'not',\n",
       "  'violence',\n",
       "  'injustice',\n",
       "  'crooked',\n",
       "  'guards',\n",
       "  'sold',\n",
       "  'nickel',\n",
       "  'inmates',\n",
       "  'kill',\n",
       "  'order',\n",
       "  'get',\n",
       "  'away',\n",
       "  'well',\n",
       "  'mannered',\n",
       "  'middle',\n",
       "  'class',\n",
       "  'inmates',\n",
       "  'turned',\n",
       "  'prison',\n",
       "  'bitches',\n",
       "  'due',\n",
       "  'lack',\n",
       "  'street',\n",
       "  'skills',\n",
       "  'prison',\n",
       "  'experience',\n",
       "  'watching',\n",
       "  'oz',\n",
       "  'may',\n",
       "  'become',\n",
       "  'comfortable',\n",
       "  'uncomfortable',\n",
       "  'viewing',\n",
       "  'thats',\n",
       "  'get',\n",
       "  'touch',\n",
       "  'darker',\n",
       "  'side'],\n",
       " ['wonderful',\n",
       "  'little',\n",
       "  'production',\n",
       "  'br',\n",
       "  'br',\n",
       "  'filming',\n",
       "  'technique',\n",
       "  'unassuming',\n",
       "  'old',\n",
       "  'time',\n",
       "  'bbc',\n",
       "  'fashion',\n",
       "  'gives',\n",
       "  'comforting',\n",
       "  'sometimes',\n",
       "  'discomforting',\n",
       "  'sense',\n",
       "  'realism',\n",
       "  'entire',\n",
       "  'piece',\n",
       "  'br',\n",
       "  'br',\n",
       "  'actors',\n",
       "  'extremely',\n",
       "  'well',\n",
       "  'chosen',\n",
       "  'michael',\n",
       "  'sheen',\n",
       "  'not',\n",
       "  'got',\n",
       "  'polari',\n",
       "  'voices',\n",
       "  'pat',\n",
       "  'truly',\n",
       "  'see',\n",
       "  'seamless',\n",
       "  'editing',\n",
       "  'guided',\n",
       "  'references',\n",
       "  'williams',\n",
       "  'diary',\n",
       "  'entries',\n",
       "  'not',\n",
       "  'well',\n",
       "  'worth',\n",
       "  'watching',\n",
       "  'terrificly',\n",
       "  'written',\n",
       "  'performed',\n",
       "  'piece',\n",
       "  'masterful',\n",
       "  'production',\n",
       "  'one',\n",
       "  'great',\n",
       "  'master',\n",
       "  'comedy',\n",
       "  'life',\n",
       "  'br',\n",
       "  'br',\n",
       "  'realism',\n",
       "  'really',\n",
       "  'comes',\n",
       "  'home',\n",
       "  'little',\n",
       "  'things',\n",
       "  'fantasy',\n",
       "  'guard',\n",
       "  'rather',\n",
       "  'use',\n",
       "  'traditional',\n",
       "  'wouldream',\n",
       "  'techniques',\n",
       "  'remains',\n",
       "  'solid',\n",
       "  'disappears',\n",
       "  'plays',\n",
       "  'knowledge',\n",
       "  'senses',\n",
       "  'particularly',\n",
       "  'scenes',\n",
       "  'concerning',\n",
       "  'orton',\n",
       "  'halliwell',\n",
       "  'sets',\n",
       "  'particularly',\n",
       "  'flat',\n",
       "  'halliwell',\n",
       "  'murals',\n",
       "  'decorating',\n",
       "  'every',\n",
       "  'surface',\n",
       "  'terribly',\n",
       "  'well',\n",
       "  'done'],\n",
       " ['thought',\n",
       "  'wonderful',\n",
       "  'way',\n",
       "  'spend',\n",
       "  'time',\n",
       "  'hot',\n",
       "  'summer',\n",
       "  'weekend',\n",
       "  'sitting',\n",
       "  'air',\n",
       "  'conditioned',\n",
       "  'theater',\n",
       "  'watching',\n",
       "  'light',\n",
       "  'hearted',\n",
       "  'comedy',\n",
       "  'plot',\n",
       "  'simplistic',\n",
       "  'dialogue',\n",
       "  'witty',\n",
       "  'characters',\n",
       "  'likable',\n",
       "  'even',\n",
       "  'well',\n",
       "  'bread',\n",
       "  'suspected',\n",
       "  'serial',\n",
       "  'killer',\n",
       "  'may',\n",
       "  'disappointed',\n",
       "  'realize',\n",
       "  'not',\n",
       "  'match',\n",
       "  'point',\n",
       "  '2',\n",
       "  'risk',\n",
       "  'addiction',\n",
       "  'thought',\n",
       "  'proof',\n",
       "  'woody',\n",
       "  'allen',\n",
       "  'still',\n",
       "  'fully',\n",
       "  'control',\n",
       "  'style',\n",
       "  'many',\n",
       "  'us',\n",
       "  'grown',\n",
       "  'love',\n",
       "  'br',\n",
       "  'br',\n",
       "  'would',\n",
       "  'laughed',\n",
       "  'one',\n",
       "  'woody',\n",
       "  'comedies',\n",
       "  'years',\n",
       "  'dare',\n",
       "  'say',\n",
       "  'decade',\n",
       "  'never',\n",
       "  'impressed',\n",
       "  'scarlet',\n",
       "  'johanson',\n",
       "  'managed',\n",
       "  'tone',\n",
       "  'sexy',\n",
       "  'image',\n",
       "  'jumped',\n",
       "  'right',\n",
       "  'average',\n",
       "  'spirited',\n",
       "  'young',\n",
       "  'woman',\n",
       "  'br',\n",
       "  'br',\n",
       "  'may',\n",
       "  'not',\n",
       "  'crown',\n",
       "  'jewel',\n",
       "  'career',\n",
       "  'wittier',\n",
       "  'devil',\n",
       "  'wears',\n",
       "  'prada',\n",
       "  'interesting',\n",
       "  'superman',\n",
       "  'great',\n",
       "  'comedy',\n",
       "  'go',\n",
       "  'see',\n",
       "  'friends']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "i = 0\n",
    "list_of_sentance = []\n",
    "for sentence in df['text_clean'].astype(str):\n",
    "    list_of_sentance.append(sentence.split())\n",
    "\n",
    "w2v_model = Word2Vec(list_of_sentance, min_count=1, vector_size=300, workers=4)\n",
    "w2v_words = list(w2v_model.wv.key_to_index.keys())\n",
    "list_of_sentance[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c007c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 49582/49582 [27:48<00:00, 29.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49582\n",
      "300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm \n",
    "# average Word2Vec\n",
    "# compute average word2vec for each review.\n",
    "sent_vectors = []; # the avg-w2v for each sentence/review is stored in this list\n",
    "for sent in tqdm(list_of_sentance): # for each sentence\n",
    "    sent_vec = np.zeros(300)\n",
    "    cnt_words =0; # num of words with a valid vector in the sentence\n",
    "    for word in sent: # for each word in a sentence\n",
    "        if word in w2v_words:\n",
    "            vec = w2v_model.wv[word]\n",
    "            sent_vec += vec\n",
    "            cnt_words += 1\n",
    "    if cnt_words != 0:\n",
    "        sent_vec /= cnt_words\n",
    "    sent_vectors.append(sent_vec)\n",
    "print(len(sent_vectors))\n",
    "print(len(sent_vectors[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27e15c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape= (49582, 300)   y shape= (49582,)\n"
     ]
    }
   ],
   "source": [
    "X=np.array(sent_vectors)\n",
    "y = df['sentiment'].values\n",
    "print(\"x shape=\",X.shape,\"  y shape=\",y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8265425b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89b5408",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29e6a4e0",
   "metadata": {},
   "source": [
    "# Gausian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cedc7ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5661 1749]\n",
      " [1739 5726]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.76      0.76      7410\n",
      "           1       0.77      0.77      0.77      7465\n",
      "\n",
      "    accuracy                           0.77     14875\n",
      "   macro avg       0.77      0.77      0.77     14875\n",
      "weighted avg       0.77      0.77      0.77     14875\n",
      "\n",
      "***AUC score***\n",
      "AUC score for NB is  0.8430074671453739\n",
      "***Accuracy score***\n",
      "Train Accuracy score for NB is  0.7639957357305442\n",
      "Test Accuracy score for NB is  0.7655126050420168\n",
      "***Recall score***\n",
      "Train recall score for NB is  0.7643377920661347\n",
      "Test recall score for NB is  0.7670462156731414\n"
     ]
    }
   ],
   "source": [
    "# Training Naive bayes\n",
    "# Finding Accuracy, AUC, False positive rate, True positive rate, confusion matrix and classificatio report\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "NB = GaussianNB()\n",
    "NB.fit(X_train, y_train)\n",
    "pred = NB.predict(X_test)\n",
    "accNB = accuracy_score(y_test, pred)\n",
    "y_pred_prob = NB.predict_proba(X_test)\n",
    "predT=NB.predict(X_train)\n",
    "aucScoreNB = roc_auc_score(y_test,  y_pred_prob[:,1])\n",
    "fprNB, tprNB, thresholds = roc_curve(y_test, y_pred_prob[:,1] )\n",
    "print(confusion_matrix(y_test,pred))\n",
    "print(classification_report(y_test,pred))\n",
    "print(\"***AUC score***\")\n",
    "print(\"AUC score for NB is \",aucScoreNB)\n",
    "print(\"***Accuracy score***\")\n",
    "print(\"Train Accuracy score for NB is \",accuracy_score(y_train, predT))\n",
    "print(\"Test Accuracy score for NB is \",accuracy_score(y_test, pred))\n",
    "print(\"***Recall score***\")\n",
    "print(\"Train recall score for NB is \",recall_score(y_train, predT))\n",
    "print(\"Test recall score for NB is \",recall_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7854150",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "183dbe88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6460  950]\n",
      " [ 907 6558]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.87      0.87      7410\n",
      "           1       0.87      0.88      0.88      7465\n",
      "\n",
      "    accuracy                           0.88     14875\n",
      "   macro avg       0.88      0.88      0.88     14875\n",
      "weighted avg       0.88      0.88      0.88     14875\n",
      "\n",
      "***AUC score***\n",
      "AUC score for LR is  0.9434809497854586\n",
      "***Accuracy score***\n",
      "Train Accuracy score for LR is  0.873887112109949\n",
      "Test Accuracy score for LR is  0.8751596638655462\n",
      "***Recall score***\n",
      "Train recall score for LR is  0.8801308915551983\n",
      "Test recall score for LR is  0.8784996651038178\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# Create a Logistic Regression classifier\n",
    "LR = LogisticRegression()\n",
    "LR.fit(X_train, y_train)\n",
    "pred = LR.predict(X_test)\n",
    "accLR = accuracy_score(y_test, pred)\n",
    "y_pred_prob = LR.predict_proba(X_test)\n",
    "predT=LR.predict(X_train)\n",
    "aucScoreLR = roc_auc_score(y_test,  y_pred_prob[:,1])\n",
    "fprLR, tprLR, thresholds = roc_curve(y_test, y_pred_prob[:,1] )\n",
    "print(confusion_matrix(y_test,pred))\n",
    "print(classification_report(y_test,pred))\n",
    "print(\"***AUC score***\")\n",
    "print(\"AUC score for LR is \",aucScoreLR)\n",
    "print(\"***Accuracy score***\")\n",
    "print(\"Train Accuracy score for LR is \",accuracy_score(y_train, predT))\n",
    "print(\"Test Accuracy score for LR is \",accuracy_score(y_test, pred))\n",
    "print(\"***Recall score***\")\n",
    "print(\"Train recall score for LR is \",recall_score(y_train, predT))\n",
    "print(\"Test recall score for LR is \",recall_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a823c1",
   "metadata": {},
   "source": [
    "# Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9f9a90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5458 1952]\n",
      " [1941 5524]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.74      0.74      7410\n",
      "           1       0.74      0.74      0.74      7465\n",
      "\n",
      "    accuracy                           0.74     14875\n",
      "   macro avg       0.74      0.74      0.74     14875\n",
      "weighted avg       0.74      0.74      0.74     14875\n",
      "\n",
      "***AUC score***\n",
      "AUC score for DT is  0.7382794019414036\n",
      "***Accuracy score***\n",
      "Train Accuracy score for DT is  1.0\n",
      "Test Accuracy score for DT is  0.7382857142857143\n",
      "***Recall score***\n",
      "Train recall score for DT is  1.0\n",
      "Test recall score for DT is  0.7399866041527127\n"
     ]
    }
   ],
   "source": [
    "# Decision Trees (Multiple if-else statements!)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# Create a DecisionTree classifier\n",
    "DT = DecisionTreeClassifier()\n",
    "DT.fit(X_train, y_train)\n",
    "pred = DT.predict(X_test)\n",
    "accDT = accuracy_score(y_test, pred)\n",
    "y_pred_prob = DT.predict_proba(X_test)\n",
    "predT=DT.predict(X_train)\n",
    "aucScoreDT = roc_auc_score(y_test,  y_pred_prob[:,1])\n",
    "fprDT, tprDT, thresholds = roc_curve(y_test, y_pred_prob[:,1] )\n",
    "print(confusion_matrix(y_test,pred))\n",
    "print(classification_report(y_test,pred))\n",
    "print(\"***AUC score***\")\n",
    "print(\"AUC score for DT is \",aucScoreDT)\n",
    "print(\"***Accuracy score***\")\n",
    "print(\"Train Accuracy score for DT is \",accuracy_score(y_train, predT))\n",
    "print(\"Test Accuracy score for DT is \",accuracy_score(y_test, pred))\n",
    "print(\"***Recall score***\")\n",
    "print(\"Train recall score for DT is \",recall_score(y_train, predT))\n",
    "print(\"Test recall score for DT is \",recall_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea44ba9",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc2d662d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6154 1256]\n",
      " [1069 6396]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.83      0.84      7410\n",
      "           1       0.84      0.86      0.85      7465\n",
      "\n",
      "    accuracy                           0.84     14875\n",
      "   macro avg       0.84      0.84      0.84     14875\n",
      "weighted avg       0.84      0.84      0.84     14875\n",
      "\n",
      "***AUC score***\n",
      "AUC score for RF is  0.9197318118832555\n",
      "***Accuracy score***\n",
      "Train Accuracy score for RF is  1.0\n",
      "Test Accuracy score for RF is  0.8436974789915966\n",
      "***Recall score***\n",
      "Train recall score for RF is  1.0\n",
      "Test recall score for RF is  0.8567983924983256\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Create a RandomForestClassifier classifier\n",
    "RF = RandomForestClassifier()\n",
    "RF.fit(X_train, y_train)\n",
    "pred = RF.predict(X_test)\n",
    "accRF = accuracy_score(y_test, pred)\n",
    "y_pred_prob = RF.predict_proba(X_test)\n",
    "predT=RF.predict(X_train)\n",
    "aucScoreRF = roc_auc_score(y_test,  y_pred_prob[:,1])\n",
    "fprRF, tprRF, thresholds = roc_curve(y_test, y_pred_prob[:,1] )\n",
    "print(confusion_matrix(y_test,pred))\n",
    "print(classification_report(y_test,pred))\n",
    "print(\"***AUC score***\")\n",
    "print(\"AUC score for RF is \",aucScoreRF)\n",
    "print(\"***Accuracy score***\")\n",
    "print(\"Train Accuracy score for RF is \",accuracy_score(y_train, predT))\n",
    "print(\"Test Accuracy score for RF is \",accuracy_score(y_test, pred))\n",
    "print(\"***Recall score***\")\n",
    "print(\"Train recall score for RF is \",recall_score(y_train, predT))\n",
    "print(\"Test recall score for RF is \",recall_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc71631",
   "metadata": {},
   "source": [
    "# XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b99c9a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6339 1071]\n",
      " [ 989 6476]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.86      0.86      7410\n",
      "           1       0.86      0.87      0.86      7465\n",
      "\n",
      "    accuracy                           0.86     14875\n",
      "   macro avg       0.86      0.86      0.86     14875\n",
      "weighted avg       0.86      0.86      0.86     14875\n",
      "\n",
      "***AUC score***\n",
      "AUC score for XGB is  0.9354951266052195\n",
      "***Accuracy score***\n",
      "Train Accuracy score for XGB is  0.9902325179358631\n",
      "Test Accuracy score for XGB is  0.8615126050420168\n",
      "***Recall score***\n",
      "Train recall score for XGB is  0.9892645961306619\n",
      "Test recall score for XGB is  0.8675150703281983\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "# Create a RandomForestClassifier classifier\n",
    "XGB = XGBClassifier()\n",
    "XGB.fit(X_train, y_train)\n",
    "pred = XGB.predict(X_test)\n",
    "accXGB = accuracy_score(y_test, pred)\n",
    "y_pred_prob = XGB.predict_proba(X_test)\n",
    "predT=XGB.predict(X_train)\n",
    "aucScoreXGB = roc_auc_score(y_test,  y_pred_prob[:,1])\n",
    "fprXGB, tprXGB, thresholds = roc_curve(y_test, y_pred_prob[:,1] )\n",
    "print(confusion_matrix(y_test,pred))\n",
    "print(classification_report(y_test,pred))\n",
    "print(\"***AUC score***\")\n",
    "print(\"AUC score for XGB is \",aucScoreXGB)\n",
    "print(\"***Accuracy score***\")\n",
    "print(\"Train Accuracy score for XGB is \",accuracy_score(y_train, predT))\n",
    "print(\"Test Accuracy score for XGB is \",accuracy_score(y_test, pred))\n",
    "print(\"***Recall score***\")\n",
    "print(\"Train recall score for XGB is \",recall_score(y_train, predT))\n",
    "print(\"Test recall score for XGB is \",recall_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74397c4",
   "metadata": {},
   "source": [
    "Logistic regression seems to be best by use of Word to Vec vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e06ae4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e889081",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
